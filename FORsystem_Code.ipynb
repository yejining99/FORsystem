{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "VrZDL_euL57y"
      },
      "source": [
        "## Imports"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "BhjG_uZT9T8g",
        "outputId": "596b101e-993a-4bf1-a925-a0a2fc6e1a80"
      },
      "outputs": [],
      "source": [
        "!pip install -q tensorflow-recommenders\n",
        "!pip install -q --upgrade tensorflow-datasets\n",
        "!pip install easydev                 #version 0.12.0\n",
        "!pip install colormap                #version 1.0.4\n",
        "!pip install opencv-python           #version 4.5.5.64\n",
        "!pip install colorgram.py            #version 1.2.0\n",
        "!pip install extcolors "
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "I8_F9Qv_gY_p"
      },
      "outputs": [],
      "source": [
        "import pandas as pd\n",
        "import numpy as np\n",
        "\n",
        "import os \n",
        "import io \n",
        "import zipfile \n",
        "from zipfile import ZipFile \n",
        "import requests \n",
        "import tensorflow as tf\n",
        "from glob import glob\n",
        "import PIL\n",
        "import PIL.Image\n",
        "from PIL import Image\n",
        "\n",
        "from tqdm import tqdm\n",
        "import time\n",
        "\n",
        "\n",
        "import pprint\n",
        "import tempfile\n",
        "\n",
        "from typing import Dict, Text\n",
        "\n",
        "import tensorflow_datasets as tfds\n",
        "import tensorflow_recommenders as tfrs\n",
        "\n",
        "import matplotlib.image as mpimg       # reading images to numpy arrays\n",
        "import matplotlib.pyplot as plt        # to plot any graph\n",
        "import matplotlib.patches as mpatches  # to draw a circle at the mean contour\n",
        "\n",
        "from skimage import measure            # to find shape contour\n",
        "import scipy.ndimage as ndi            # to determine shape centrality\n",
        "\n",
        "import matplotlib.pyplot as plt\n",
        "import matplotlib.patches as patches\n",
        "import matplotlib.image as mpimg\n",
        "\n",
        "from PIL import Image\n",
        "from matplotlib.offsetbox import OffsetImage, AnnotationBbox\n",
        "\n",
        "import cv2\n",
        "import extcolors\n",
        "\n",
        "from colormap import rgb2hex\n",
        "\n",
        "\n",
        "from skimage.io import imread, imshow, imread_collection, imshow_collection\n",
        "from skimage.transform import rescale, resize, downscale_local_mean\n",
        "\n",
        "\n",
        "# matplotlib setup\n",
        "%matplotlib inline\n",
        "from pylab import rcParams\n",
        "rcParams['figure.figsize'] = (6,6) "
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "iFmS9N6NSrrt",
        "outputId": "41148ed4-d7b8-448d-f5b2-fd31907a9e3e"
      },
      "outputs": [],
      "source": [
        "from google.colab import drive\n",
        "drive.mount('/content/drive')"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "1NgYiQLP97QK"
      },
      "source": [
        "# preparing the dataset"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "hvYQDksLwviE"
      },
      "outputs": [],
      "source": [
        "# ZIP 파일 풀어주기\n",
        "\"\"\"\n",
        "path_to_zip_file = '/content/drive/MyDrive/kaggle/H&M/data/h-and-m-personalized-fashion-recommendations.zip'\n",
        "directory_to_extract_to = '/content/drive/MyDrive/kaggle/H&M/data'\n",
        "\n",
        "import zipfile\n",
        "with zipfile.ZipFile(path_to_zip_file, 'r') as zip_ref:\n",
        "    zip_ref.extractall(directory_to_extract_to)\n",
        "\"\"\""
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "eycMqrryC-dj"
      },
      "outputs": [],
      "source": [
        "#읽어오기\n",
        "articles = pd.read_csv('/content/drive/MyDrive/kaggle/H&M/data/articles.csv')\n",
        "customers = pd.read_csv('/content/drive/MyDrive/kaggle/H&M/data/customers.csv')\n",
        "sample_submission = pd.read_csv('/content/drive/MyDrive/kaggle/H&M/data/sample_submission.csv')\n",
        "transactions = pd.read_csv('/content/drive/MyDrive/kaggle/H&M/data/transactions_train.csv')"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "65bfX8hcBYa4",
        "outputId": "083c62d1-46ae-4e13-c93f-a2761f4cbcdc"
      },
      "outputs": [],
      "source": [
        "transactions.info()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "J7zFStPWCIAs"
      },
      "outputs": [],
      "source": [
        "customer_id_list = transactions['customer_id'].unique()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "StM2Lj0aEeh3"
      },
      "outputs": [],
      "source": [
        "# customer_id 10000개만 사용\n",
        "transactions_train = transactions.sort_values(by=['customer_id'])\n",
        "transactions_train = transactions_train.reset_index(drop=True)\n",
        "transactions_train = transactions_train[:237300]"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "mIHloTYKe43L"
      },
      "source": [
        "# Image feature extraction"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "zJ0fsXQ8b-Vo"
      },
      "source": [
        "### color extraction\n",
        "\n",
        "https://towardsdatascience.com/image-color-extraction-with-python-in-4-steps-8d9370d9216e"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "VXd9GQR8TykA"
      },
      "outputs": [],
      "source": [
        "article_id_list = transactions_train['article_id'].unique().astype('str')"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "ffS2c138ZDMk"
      },
      "outputs": [],
      "source": [
        "article_id_list = list(map(lambda x:'0'+x, article_id_list))"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "-u_DO2EYW7OH",
        "outputId": "5e7dad49-3db6-4ce2-81b0-44a3b6a0cfba"
      },
      "outputs": [],
      "source": [
        "'745232001' in article_id_list"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "ovFZlplNW3EO",
        "outputId": "942a7a0e-a57e-4b62-cd59-3037be5014c9"
      },
      "outputs": [],
      "source": [
        "'0389388001' in article_id_list"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "pryhI6AChYSV",
        "outputId": "2f172554-9d09-4372-8c72-0f7f5f876a14"
      },
      "outputs": [],
      "source": [
        "import os\n",
        "path_dir = '../content/drive/MyDrive/kaggle/H&M/data/images'\n",
        "file_list = os.listdir(path_dir)\n",
        "\n",
        "image_name = []\n",
        "\n",
        "for lis in file_list:\n",
        "  sub_list = path_dir+'/'+lis\n",
        "  sub_file_list = os.listdir(sub_list)\n",
        "  for img in sub_file_list:\n",
        "    img_name = img[:-4]\n",
        "    if img_name in article_id_list:\n",
        "      print(img_name,'가 존재')\n",
        "      img = sub_list+'/'+img\n",
        "      image_name.append(img)\n",
        "    else:\n",
        "      print(img_name,'가 없음')"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "P85kWgk798jL"
      },
      "outputs": [],
      "source": [
        "def color_to_df(input):\n",
        "    colors_pre_list = str(input).replace('([(','').split(', (')[0:-1]\n",
        "    df_rgb = [i.split('), ')[0] + ')' for i in colors_pre_list]\n",
        "    df_percent = [int(i.split('), ')[1].replace(')','')) for i in colors_pre_list]\n",
        "\n",
        "    #convert RGB to HEX code\n",
        "    df_color_up = [rgb2hex(int(i.split(\", \")[0].replace(\"(\",\"\")),\n",
        "                          int(i.split(\", \")[1]),\n",
        "                          int(i.split(\", \")[2].replace(\")\",\"\"))) for i in df_rgb]\n",
        " \n",
        "    return df_color_up"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "ljwhjg9orORY"
      },
      "outputs": [],
      "source": [
        "def exact_color(input_image, resize, tolerance, zoom, dic):\n",
        "    resize_name =  input_image\n",
        "    \n",
        "    #crate dataframe\n",
        "    img_url = resize_name\n",
        "    colors_x = extcolors.extract_from_path(img_url, tolerance = tolerance, limit = 13)\n",
        "    color_list = color_to_df(colors_x)\n",
        "    name = resize_name[-14:-4]\n",
        "    dic[name] = ' '.join(color_list)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "q2cLJXfDjRkG"
      },
      "outputs": [],
      "source": [
        "ex = image_name[155]"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "x05kzP-pA_DX",
        "outputId": "913fc175-a3f7-402e-ffb7-f268682bf589"
      },
      "outputs": [],
      "source": [
        "color_dic = {}\n",
        "for i in tqdm(image_name):\n",
        "  exact_color(i,900,30,1.2,color_dic)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "o81LNKZLCyIX"
      },
      "outputs": [],
      "source": [
        "df_color_dic = pd.DataFrame(list(color_dic.items()),columns=['name','color'])"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "raNWvtKlFWCM"
      },
      "outputs": [],
      "source": [
        "df_color_dic.to_csv('/content/drive/MyDrive/kaggle/H&M/data/image_colors.csv')"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "OBb71ZVomvtY",
        "outputId": "743e717c-45a5-4fb9-9e1c-9e975aa14b14"
      },
      "outputs": [],
      "source": [
        "len(image_name)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "uqF5VcfqjjDy"
      },
      "outputs": [],
      "source": [
        "from pandas.core.groupby.generic import DataFrameGroupBy\n",
        "# 시각화\n",
        "def color_to_df(input):\n",
        "    colors_pre_list = str(input).replace('([(','').split(', (')[0:-1]\n",
        "    df_rgb = [i.split('), ')[0] + ')' for i in colors_pre_list]\n",
        "    df_percent = [i.split('), ')[1].replace(')','') for i in colors_pre_list]\n",
        "    \n",
        "    #convert RGB to HEX code\n",
        "    df_color_up = [rgb2hex(int(i.split(\", \")[0].replace(\"(\",\"\")),\n",
        "                          int(i.split(\", \")[1]),\n",
        "                          int(i.split(\", \")[2].replace(\")\",\"\"))) for i in df_rgb]\n",
        "    \n",
        "    df = pd.DataFrame(zip(df_color_up, df_percent), columns = ['c_code','occurence'])\n",
        "\n",
        "    # 배경 지우기\n",
        "    if len(df[df['c_code'].str.contains('FFF',)]) != 0:\n",
        "      df = df[~df['c_code'].str.contains(\"FFF\", na=False, case=False)]\n",
        "    else:\n",
        "      df = df[1:]\n",
        "\n",
        "    df = df[:5]\n",
        "    return df\n",
        "\n",
        "def exact_color(input_image, resize, tolerance, zoom):\n",
        "    #background\n",
        "    bg = 'bg.png'\n",
        "    fig, ax = plt.subplots(figsize=(192,108),dpi=10)\n",
        "    fig.set_facecolor('white')\n",
        "    plt.savefig(bg)\n",
        "    plt.close(fig)\n",
        "    \n",
        "    resize_name = input_image\n",
        "    \n",
        "    #crate dataframe\n",
        "    img_url = resize_name\n",
        "    colors_x = extcolors.extract_from_path(img_url, tolerance = tolerance, limit = 13)\n",
        "    df_color = color_to_df(colors_x)\n",
        "    \n",
        "    #annotate text\n",
        "    list_color = list(df_color['c_code'])\n",
        "    list_precent = [int(i) for i in list(df_color['occurence'])]\n",
        "    text_c = [c + ' ' + str(round(p*100/sum(list_precent),1)) +'%' for c, p in zip(list_color, list_precent)]\n",
        "    fig, (ax1, ax2) = plt.subplots(1, 2, figsize=(160,120), dpi = 10)\n",
        "    \n",
        "    #donut plot\n",
        "    wedges, text = ax1.pie(list_precent,\n",
        "                           labels= text_c,\n",
        "                           labeldistance= 1.05,\n",
        "                           colors = list_color,\n",
        "                           textprops={'fontsize': 150, 'color':'black'})\n",
        "    plt.setp(wedges, width=0.3)\n",
        "\n",
        "    #add image in the center of donut plot\n",
        "    img = mpimg.imread(resize_name)\n",
        "    imagebox = OffsetImage(img, zoom=zoom)\n",
        "    ab = AnnotationBbox(imagebox, (0, 0))\n",
        "    ax1.add_artist(ab)\n",
        "    \n",
        "    #color palette\n",
        "    x_posi, y_posi, y_posi2 = 160, -170, -170\n",
        "    for c in list_color:\n",
        "        if list_color.index(c) <= 5:\n",
        "            y_posi += 180\n",
        "            rect = patches.Rectangle((x_posi, y_posi), 360, 160, facecolor = c)\n",
        "            ax2.add_patch(rect)\n",
        "            ax2.text(x = x_posi+400, y = y_posi+100, s = c, fontdict={'fontsize': 190})\n",
        "        else:\n",
        "            y_posi2 += 180\n",
        "            rect = patches.Rectangle((x_posi + 1000, y_posi2), 360, 160, facecolor = c)\n",
        "            ax2.add_artist(rect)\n",
        "            ax2.text(x = x_posi+1400, y = y_posi2+100, s = c, fontdict={'fontsize': 190})\n",
        "\n",
        "    fig.set_facecolor('white')\n",
        "    ax2.axis('off')\n",
        "    bg = plt.imread('bg.png')\n",
        "    plt.imshow(bg)       \n",
        "    plt.tight_layout()\n",
        "    plt.savefig('color.jpg')\n",
        "    return plt.show()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "n-tkFy85u6vQ",
        "outputId": "9481451f-792e-4300-99bb-802ee5b83cb7"
      },
      "outputs": [],
      "source": [
        "len(image_name)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "pfWS9hCEj4d1",
        "outputId": "42c0289f-9c25-4903-9ca2-cf7f23f816c8"
      },
      "outputs": [],
      "source": [
        "# 155\n",
        "ex = image_name[83350]\n",
        "imshow(ex)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "TxoA5oUcjjAX",
        "outputId": "93242076-8880-4e10-a838-4dc34b1cfdc1"
      },
      "outputs": [],
      "source": [
        "exact_color(ex, 1, 30, 1.3)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "jQVV1c7ZcPhs"
      },
      "source": [
        "### shape extraction"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "fejuRZyGewyf"
      },
      "outputs": [],
      "source": [
        "img = cv2.imread(ex, cv2.IMREAD_GRAYSCALE)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "8qMcrKSGewva",
        "outputId": "688a9792-77b2-4143-cb08-10027547e946"
      },
      "outputs": [],
      "source": [
        "robertsx = np.array([[-1,0,0],[0,1,0],[0,0,0]])\n",
        "robertsy = np.array([[0,0,-1],[0,1,0],[0,0,0]])\n",
        "\n",
        "robertsX = cv2.filter2D(img, cv2.CV_64F, robertsx)\n",
        "robertsY = cv2.filter2D(img, cv2.CV_64F, robertsx)\n",
        "\n",
        "prewittx = np.array([[-1,0,1],[-1,0,1],[-1,0,1]])\n",
        "prewitty = np.array([[-1,-1,-1],[0,0,0],[1,1,1]])\n",
        "prewitt_ = np.array([[-1,-1,0],[-1,0,1],[0,1,1]])\n",
        "\n",
        "prewittX = cv2.filter2D(img, -1, prewittx)\n",
        "prewittY = cv2.filter2D(img, -1, prewitty)\n",
        "prewitt_ = cv2.filter2D(img, -1, prewitt_)\n",
        "\n",
        "sobelX = cv2.Sobel(img, -1,1,0,ksize=3)\n",
        "sobelY = cv2.Sobel(img, -1,0,1,ksize=3)\n",
        "sobel = sobelX + sobelY\n",
        "\n",
        "scharrX = cv2.Sobel(img, -1,1,0,ksize = cv2.FILTER_SCHARR)\n",
        "scharrY = cv2.Sobel(img,-1,0,1,ksize=-1)\n",
        "scharr = scharrX+scharrY\n",
        "\n",
        "titles = ['original', 'robers-X', 'robers-Y', 'prewitt-X', 'prewitt-Y', 'prewitt_', 'sobel-X', 'sobel-Y', 'sobel', 'scharr-X', 'scharr-Y', 'scharr']\n",
        "images = [img, robertsX, robertsY, prewittX, prewittY, prewitt_, sobelX, sobelY, sobel, scharrX, scharrY, scharr]\n",
        "\n",
        "#cv2_imshow(img)\n",
        "#cv2_imshow(prewitt_)\n",
        "#cv2_imshow(sobel)\n",
        "#cv2_imshow(scharr)\n",
        "#cv2.waitKey(0)\n",
        "#cv2.destroyAllWindows()\n",
        "\n",
        "plt.figure(figsize = (12,6))\n",
        "for i in range(12):\n",
        "  plt.subplot(2,6,i+1)\n",
        "  plt.imshow(images[i],cmap='gray')\n",
        "  plt.title(titles[i])\n",
        "  plt.axis('off')\n",
        "\n",
        "plt.tight_layout()\n",
        "plt.savefig('shape.png')\n",
        "plt.show()"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "GeSnGxmFTU-s"
      },
      "source": [
        "# Language feature extraction"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "T9jic6beat_M"
      },
      "outputs": [],
      "source": [
        "key_list = pd.read_csv('/content/drive/MyDrive/kaggle/H&M/data/key_list.csv', header=None, names = ['key_list'])"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "W82nmQhoat1A"
      },
      "outputs": [],
      "source": [
        "articles_key_list = pd.concat([articles['article_id'],key_list],axis=1)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "Wj_CyMwddd7i"
      },
      "outputs": [],
      "source": [
        "articles_key_list['article_id'] = articles_key_list['article_id'].apply(str)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "HDOxwBU6fljq"
      },
      "outputs": [],
      "source": [
        "articles_key_list = articles_key_list.fillna('no')"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "8rsTDe_5e6nf",
        "outputId": "d0db8eb9-c388-4c8d-8153-327735b3ea0a"
      },
      "outputs": [],
      "source": [
        "articles_key_list.info()"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "I7mQvN8PcKtX"
      },
      "source": [
        "# Transactions 데이터 가공"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "JtvNcKH4-TYZ"
      },
      "outputs": [],
      "source": [
        "# 시간데이터,문자열로 변경\n",
        "transactions_train['t_dat'] = pd.to_datetime(transactions_train['t_dat'])\n",
        "transactions_train['article_id'] = transactions_train['article_id'].apply(str)\n",
        "transactions_train['sales_channel_id'] = transactions_train['sales_channel_id'].apply(str) "
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "0rgm9yrHHqzT",
        "outputId": "2f955301-41e2-4740-827e-42e22bee6391"
      },
      "outputs": [],
      "source": [
        "transactions_train.info()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "y7sind7JYpwE"
      },
      "outputs": [],
      "source": [
        "window = 10\n",
        "lag = 1\n",
        "train_article = transactions_train\n",
        "train_time = transactions_train\n",
        "train_price = transactions_train"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "kLJcuIzHQLEA"
      },
      "outputs": [],
      "source": [
        "# article_id\n",
        "for i in range(-1, -1*(window+lag),-1):\n",
        "  shift_df = transactions_train.groupby(by='customer_id')['article_id'].shift(i)\n",
        "  train_article = train_article.join(shift_df.rename(\"article_id\"+str(i)))\n",
        "  train_article = train_article.dropna()\n",
        "\n",
        "# 시간\n",
        "for j in range(-1, -1*(window+lag),-1):\n",
        "  shift_time = transactions_train.groupby(by='customer_id')['t_dat'].shift(j)\n",
        "  train_time = train_time.join(shift_time.rename(\"t_dat\"+str(j)))\n",
        "  train_time = train_time.dropna()\n",
        "\n",
        "\n",
        "# price\n",
        "for k in range(-1, -1*(window+lag),-1):\n",
        "  shift_price = transactions_train.groupby(by='customer_id')['price'].shift(k)\n",
        "  train_price = train_price.join(shift_price.rename(\"price\"+str(k)))\n",
        "  train_price = train_price.dropna()\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "09qHjaORY6xg"
      },
      "outputs": [],
      "source": [
        "train_article = train_article.drop(['t_dat', 'customer_id','price','sales_channel_id'],axis=1)\n",
        "train_time = train_time.drop(['customer_id','article_id','price','sales_channel_id','t_dat-10'],axis=1)\n",
        "train_price = train_price.drop(['t_dat','customer_id','article_id','sales_channel_id','price-10'],axis=1)\n",
        "train_target = train_article.pop('article_id'+str(-1*(window+lag-1)))"
      ]
    },
    {
      "attachments": {},
      "cell_type": "markdown",
      "metadata": {
        "id": "LVRCmRP37izI"
      },
      "source": [
        "# articles data preprocessing"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "eP3mj4sN3iuB",
        "outputId": "b7ef0667-a440-4091-b0d8-ee4523a7541a"
      },
      "outputs": [],
      "source": [
        "articles_train = articles[['article_id','product_type_name','graphical_appearance_name','section_name']]\n",
        "articles_train['article_id'] = articles_train['article_id'].apply(str)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "6trCPpcV30MC",
        "outputId": "939cb705-9d08-4bbb-d41b-cd154a33b872"
      },
      "outputs": [],
      "source": [
        "articles_train.info()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "hc-0N6VF36Eb"
      },
      "outputs": [],
      "source": [
        "article_train_merge = pd.merge(left=transactions_train, right=articles_train, how='left',on='article_id')"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 713
        },
        "id": "uOwxRlLT36Bh",
        "outputId": "820f171c-9759-4439-fcb1-86c7543ddf39"
      },
      "outputs": [],
      "source": [
        "article_train_merge"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "8KYMT2Mq5z23"
      },
      "outputs": [],
      "source": [
        "def window_df(df,col_name, window, lag):\n",
        "  train_df = df\n",
        "  for i in range(-1, -1*(window+lag),-1):\n",
        "    shift_df = df.groupby(by='customer_id')[col_name].shift(i)\n",
        "    train_df = train_df.join(shift_df.rename(col_name+str(i)))\n",
        "    train_df = train_df.dropna()\n",
        "  return train_df"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "ccVxCA1v50Ud"
      },
      "outputs": [],
      "source": [
        "train_product_type_name = window_df(article_train_merge,'product_type_name',10,1)\n",
        "train_graphical_appearance = window_df(article_train_merge,'graphical_appearance_name',10,1)\n",
        "train_section_name =window_df(article_train_merge,'section_name',10,1)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "kImghjLf6n4Y"
      },
      "outputs": [],
      "source": [
        "train_product_type_name = train_product_type_name.drop(['t_dat', 'customer_id','article_id','price','sales_channel_id','graphical_appearance_name','section_name','product_type_name-10'],axis=1)\n",
        "train_graphical_appearance = train_graphical_appearance.drop(['t_dat', 'customer_id','article_id','price','sales_channel_id','product_type_name','section_name','graphical_appearance_name-10'],axis=1)\n",
        "train_section_name = train_section_name.drop(['t_dat', 'customer_id','article_id','price','sales_channel_id','graphical_appearance_name','product_type_name','section_name-10'],axis=1)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "0wGbFUzndCSK"
      },
      "source": [
        "## language 데이터 가공"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "T3BBCMSBdMSm"
      },
      "outputs": [],
      "source": [
        "key_list_merge = pd.merge(left=transactions_train, right=articles_key_list, how='left',on='article_id')"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 468
        },
        "id": "e8S1FVK7dJXx",
        "outputId": "6da19409-1c5d-43ba-88df-82fddde182c9"
      },
      "outputs": [],
      "source": [
        "key_list_merge"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "gDhlrdeydoHq"
      },
      "outputs": [],
      "source": [
        "train_key_list = window_df(key_list_merge, 'key_list',10,1)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "4hOz2o3OdJXy"
      },
      "outputs": [],
      "source": [
        "train_key_list = train_key_list.drop(['t_dat', 'customer_id','article_id','price','sales_channel_id','key_list-10'],axis=1)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "IzsMFPEXeQY6"
      },
      "source": [
        "# from tensor slices"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "9yr-PuggGKFV"
      },
      "outputs": [],
      "source": [
        "article_index = list(train_article.index)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "oOVVBbJNGoDO"
      },
      "outputs": [],
      "source": [
        "import random"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "hyKbD2cclJRt"
      },
      "outputs": [],
      "source": [
        "test_index = random.sample(article_index, int(len(article_index)*0.2))"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "N7VryO9Mkv5P"
      },
      "outputs": [],
      "source": [
        "# 전체 저장\n",
        "all_article = train_article                         \n",
        "all_product_type_name = train_product_type_name\n",
        "all_graphical_appearance = train_graphical_appearance\n",
        "all_section_name = train_section_name\n",
        "all_price = train_price\n",
        "all_key_list = train_key_list\n",
        "all_target = train_target"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "urhQwkhQkIaa"
      },
      "outputs": [],
      "source": [
        "test_article = train_article.loc[test_index]                                      \n",
        "test_product_type_name = train_product_type_name.loc[test_index]   \n",
        "test_graphical_appearance =train_graphical_appearance.loc[test_index]   \n",
        "test_section_name =train_section_name.loc[test_index]  \n",
        "test_price =train_price.loc[test_index]  \n",
        "test_key_list = train_key_list.loc[test_index]   \n",
        "test_target = train_target.loc[test_index]   "
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "NaK2HJjlj4g1"
      },
      "outputs": [],
      "source": [
        "train_article = train_article.drop(test_index, axis=0)                             \n",
        "train_product_type_name = train_product_type_name.drop(test_index, axis=0)\n",
        "train_graphical_appearance = train_graphical_appearance.drop(test_index, axis=0)\n",
        "train_section_name = train_section_name.drop(test_index, axis=0)\n",
        "train_price = train_price.drop(test_index, axis=0)\n",
        "train_key_list = train_key_list.drop(test_index, axis=0)\n",
        "train_target = train_target.drop(test_index, axis=0)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "GcD_z_c_IFbm"
      },
      "outputs": [],
      "source": [
        "train = tf.data.Dataset.from_tensor_slices({\"context_article_id\":train_article.values,            \n",
        "                                            \"product_type_name\":train_product_type_name.values,\n",
        "                                            \"graphical_appearance\" :train_graphical_appearance.values,\n",
        "                                            \"section_name\":train_section_name.values,\n",
        "                                            \"price\" : train_price.values, \n",
        "                                            \"key_list\" : train_key_list.values,\n",
        "                                            \"label_article_id\":train_target.values})\n",
        "\n",
        "test = tf.data.Dataset.from_tensor_slices({\"context_article_id\":test_article.values,\n",
        "                                            \"product_type_name\":test_product_type_name.values,\n",
        "                                            \"graphical_appearance\" :test_graphical_appearance.values,\n",
        "                                            \"section_name\":test_section_name.values,\n",
        "                                            \"price\" : test_price.values, \n",
        "                                            \"key_list\" : test_key_list.values,\n",
        "                                            \"label_article_id\":test_target.values})"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "J9MZ6jO3IgTe",
        "outputId": "12b7ac82-3ee5-4e9e-adb9-c1ed170dfb08"
      },
      "outputs": [],
      "source": [
        "for x in train.take(1).as_numpy_iterator():\n",
        "  pprint.pprint(x)"
      ]
    },
    {
      "attachments": {},
      "cell_type": "markdown",
      "metadata": {
        "id": "PtyVB3A9bRQ0"
      },
      "source": [
        "# test"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "_hgWh4vkYS-t"
      },
      "outputs": [],
      "source": [
        "def window_lag(data, features , window=10, lag=1, dropnan=True):\n",
        "    cols, names = list(),list()\n",
        "    for i in range(window-1, 0, -1):\n",
        "        cols.append(data[features].shift(i))\n",
        "        names += [('%s(t-%d)'%(col,i)) for col in data[features].columns]\n",
        "    cols.append(data[features])\n",
        "    names += [('%s(t)'%(col)) for col in data[features].columns]\n",
        "\n",
        "    for j in range(lag):\n",
        "        cols.append(data[features].shift(-lag))\n",
        "        names += [('%s(t+%d)'%(col,lag)) for col in data[features].columns]\n",
        "\n",
        "        agg = pd.concat(cols, axis=1)\n",
        "        agg.columns = names\n",
        "\n",
        "        test_agg = agg.iloc[-1]\n",
        "\n",
        "    if dropnan:\n",
        "        agg.dropna(inplace=True)\n",
        "\n",
        "        cut = int(0.9*len(agg))\n",
        "\n",
        "        train_agg = agg[:cut]\n",
        "        valid_agg = agg[cut:]\n",
        "\n",
        "\n",
        "    return train_agg, valid_agg, test_agg\n",
        "\n",
        "def list_chunk(lst,n):\n",
        "    return [lst[i:i+n] for i in range(0, len(lst), n)]\n",
        "\n",
        "def all_window_lag(data,id, features , window=1, lag=1, dropnan=True):\n",
        "    customers = data[id].unique()\n",
        "    chunk_customers = list_chunk(customers,10000)\n",
        "\n",
        "    print('the number of chunk: ', len(chunk_customers))\n",
        "\n",
        "    # 나중에 전체 customers로 바꾸기\n",
        "    cnt = 0\n",
        "    for chunk in chunk_customers[:2]:\n",
        "        cnt += 1\n",
        "        train = pd.DataFrame()\n",
        "        valid = pd.DataFrame()\n",
        "        test = pd.DataFrame()\n",
        "\n",
        "        for cus in tqdm(chunk):\n",
        "            train_agg, valid_agg, test_agg = window_lag(data[data[id]==cus],features,window,lag)\n",
        "            train = train.append(train_agg)\n",
        "            valid = valid.append(valid_agg)\n",
        "            test = test.append(test_agg)\n",
        "\n",
        "        train.to_csv('train_'+str(cnt)+'.csv')\n",
        "        valid.to_csv('valid_'+str(cnt)+'.csv')\n",
        "        test.to_csv('test_'+str(cnt)+'.csv')\n",
        "\n",
        "    return train, valid, test\n",
        "\n",
        "    \n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "background_save": true,
          "base_uri": "https://localhost:8080/",
          "height": 99
        },
        "id": "vcZw-X6Zg9XD",
        "outputId": "05a81478-8fbe-4565-c0c2-c3c7796d6679"
      },
      "outputs": [],
      "source": [
        "window = 10\n",
        "lag = 1\n",
        "all_window_lag(transactions_train, 'customer_id',['article_id'], window, lag)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "fhmRAeN0IBb-"
      },
      "outputs": [],
      "source": [
        "#train과 valid 이어붙이는거\n",
        "path = \"/content/drive/MyDrive/kaggle/H&M/data/transaction_chunk\"\n",
        "file_list = os.listdir(path)\n",
        "\n",
        "train_list = [i for i in file_list if 'train' in i]\n",
        "valid_list = [j for j in file_list if 'valid' in j]\n",
        "test_list = [k for k in file_list if 'test' in k]\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "KGfZGpq7TTkl"
      },
      "outputs": [],
      "source": [
        "def concat_the_file(lis):\n",
        "  df = pd.DataFrame()\n",
        "  for name in lis:\n",
        "    dd = pd.read_csv('/content/drive/MyDrive/kaggle/H&M/data/transaction_chunk/'+ name )\n",
        "    df = pd.concat([df,dd])\n",
        "\n",
        "  return df"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "MRqQeHYgTz7T"
      },
      "outputs": [],
      "source": [
        "train = concat_the_file(train_list)\n",
        "valid = concat_the_file(valid_list)\n",
        "test = concat_the_file(test_list)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "NjQuPlfPY84F"
      },
      "outputs": [],
      "source": [
        "#article_id를 str형태로 바꿔주기\n",
        "train = train.applymap(str)\n",
        "valid = train.applymap(str)\n",
        "test = train.applymap(str)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "ALxXrugaZmGV"
      },
      "source": [
        "# Implementing a sequential model"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "xS48ERhYjvNJ"
      },
      "outputs": [],
      "source": [
        "max_price = transactions_train.price.max()\n",
        "min_price = transactions_train.price.min()\n",
        "\n",
        "price_buckets = np.linspace(\n",
        "    min_price, max_price, num=100000,\n",
        ")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "__0KSU_rlKFR"
      },
      "outputs": [],
      "source": [
        "all_article = train_article                         \n",
        "all_product_type_name = train_product_type_name\n",
        "all_graphical_appearance = train_graphical_appearance\n",
        "all_section_name = train_section_name\n",
        "all_price = train_price\n",
        "all_key_list = train_key_list\n",
        "all_target = train_target"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "W_0cvlOOnLXk"
      },
      "outputs": [],
      "source": [
        "#model\n",
        "embedding_dimension = 128\n",
        "unique_articles_ids = all_article['article_id'].unique()\n",
        "unique_product_type = all_product_type_name['product_type_name'].unique()\n",
        "unique_graphical_appearance = all_graphical_appearance['graphical_appearance_name'].unique()\n",
        "unique_section_name = all_section_name['section_name'].unique()\n",
        "unique_key_list = all_key_list['key_list'].unique()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "vBADNWSelpCp"
      },
      "outputs": [],
      "source": [
        "class query_model(tf.keras.Model):\n",
        "\n",
        "  def __init__(self):\n",
        "    super().__init__()\n",
        "\n",
        "    self.user_embedding =  tf.keras.Sequential([\n",
        "                                      tf.keras.layers.StringLookup(\n",
        "                                          vocabulary=unique_articles_ids, mask_token=None),\n",
        "                                      tf.keras.layers.Embedding(len(unique_articles_ids) + 1, embedding_dimension),\n",
        "    ])\n",
        "\n",
        "    self.product_type_embedding = tf.keras.Sequential([\n",
        "                                      tf.keras.layers.StringLookup(\n",
        "                                          vocabulary=unique_product_type, mask_token=None),\n",
        "                                      tf.keras.layers.Embedding(len(unique_product_type) + 1, embedding_dimension),\n",
        "    ])\n",
        "\n",
        "    self.graphical_appearance_embedding = tf.keras.Sequential([\n",
        "                                      tf.keras.layers.StringLookup(\n",
        "                                          vocabulary=unique_graphical_appearance, mask_token=None),\n",
        "                                      tf.keras.layers.Embedding(len(unique_graphical_appearance) + 1, embedding_dimension),\n",
        "    ])\n",
        "\n",
        "    self.section_embedding = tf.keras.Sequential([\n",
        "                                      tf.keras.layers.StringLookup(\n",
        "                                          vocabulary=unique_section_name, mask_token=None),\n",
        "                                      tf.keras.layers.Embedding(len(unique_section_name) + 1, embedding_dimension),\n",
        "    ])\n",
        "\n",
        "    self.price_embedding = tf.keras.Sequential([\n",
        "                                       tf.keras.layers.Discretization(price_buckets.tolist()),\n",
        "                                       tf.keras.layers.Embedding(len(price_buckets) + 1, embedding_dimension),\n",
        "    ])\n",
        "\n",
        "    self.key_list_embedding = tf.keras.Sequential([\n",
        "                                      tf.keras.layers.StringLookup(\n",
        "                                          vocabulary=unique_key_list, mask_token=None),\n",
        "                                      tf.keras.layers.Embedding(len(unique_key_list) + 1, embedding_dimension),\n",
        "    ])\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "  def call(self, inputs):\n",
        "    return tf.concat([\n",
        "        self.user_embedding(inputs[\"context_article_id\"]),\n",
        "        self.product_type_embedding(inputs[\"product_type_name\"]),\n",
        "        self.graphical_appearance_embedding(inputs[\"graphical_appearance\"]),\n",
        "        self.section_embedding(inputs[\"section_name\"]),\n",
        "        self.price_embedding(inputs[\"price\"]),\n",
        "        self.key_list_embedding(inputs[\"key_list\"])\n",
        "        ], axis=1)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "HiJ65_yyIgOP"
      },
      "outputs": [],
      "source": [
        "candidate_model = tf.keras.Sequential([\n",
        "  tf.keras.layers.StringLookup(\n",
        "      vocabulary=unique_articles_ids, mask_token=None),\n",
        "  tf.keras.layers.Embedding(len(unique_articles_ids) + 1, embedding_dimension)\n",
        "])"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "Tr9hifpLIgLB"
      },
      "outputs": [],
      "source": [
        "articles = tf.data.Dataset.from_tensor_slices(unique_articles_ids)\n",
        "\n",
        "metrics = tfrs.metrics.FactorizedTopK(\n",
        "    candidates=articles.batch(128).map(candidate_model)\n",
        ")\n",
        "\n",
        "task = tfrs.tasks.Retrieval(\n",
        "  metrics=metrics\n",
        ")\n",
        "\n",
        "class Model(tfrs.models.Model):\n",
        "\n",
        "    def __init__(self, query_model, candidate_model):\n",
        "        super().__init__()\n",
        "        self._query_model = tf.keras.Sequential([\n",
        "                                                 query_model,\n",
        "                                                 #tf.keras.layers.Dense(embedding_dimension),\n",
        "                                                 tf.keras.layers.GRU(embedding_dimension)\n",
        "                                                 ])\n",
        "        self._candidate_model = candidate_model\n",
        "\n",
        "        self._task = task\n",
        "\n",
        "    def compute_loss(self, features, training=False):\n",
        "        query_embedding = self._query_model({\n",
        "            \"context_article_id\": features[\"context_article_id\"],\n",
        "            \"product_type_name\": features[\"product_type_name\"],\n",
        "            \"graphical_appearance\": features[\"graphical_appearance\"],\n",
        "            \"section_name\": features[\"section_name\"],\n",
        "            \"price\" : features[\"price\"],\n",
        "            \"key_list\" : features[\"key_list\"]\n",
        "\n",
        "          })       \n",
        "        candidate_embedding = self._candidate_model(features[\"label_article_id\"])\n",
        "\n",
        "        return self._task(query_embedding, candidate_embedding, compute_metrics=not training)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "RCFDjiHFIFV_"
      },
      "outputs": [],
      "source": [
        "#model fitting\n",
        "query_model = query_model()\n",
        "model = Model(query_model, candidate_model)\n",
        "model.compile(optimizer=tf.keras.optimizers.Adagrad(learning_rate=0.01))"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "pLUaVM9GbNEY"
      },
      "outputs": [],
      "source": [
        "cached_train = train.shuffle(10_000).batch(12800).cache()#cached_test = valid.batch(2560).cache()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "va8WiOuqM00n"
      },
      "outputs": [],
      "source": [
        "cached_test = test.shuffle(10_000).batch(2560).cache()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "zgqJ4W2FvmJk",
        "outputId": "2987be9f-d4c4-484e-9ad8-70e4e2108764"
      },
      "outputs": [],
      "source": [
        "model1_data = model.fit(cached_train, epochs=10)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "dFPkIe2E-eMz",
        "outputId": "a54cf442-30c8-4faf-9dd7-a0f33cbf7325"
      },
      "outputs": [],
      "source": [
        "# article, price, product type name, graphical appearance name, section name\n",
        "model.evaluate(cached_test, return_dict=True)"
      ]
    },
    {
      "attachments": {},
      "cell_type": "markdown",
      "metadata": {
        "id": "HlvwbYQ9TwpU"
      },
      "source": [
        "# without feature"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "7lYwQnDFUqTE"
      },
      "source": [
        "#### from tensor slices"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "QLzP2BcKUqTO"
      },
      "outputs": [],
      "source": [
        "train = tf.data.Dataset.from_tensor_slices({\"context_article_id\":train_article.values,            \n",
        "                                            \"label_article_id\":train_target.values})\n",
        "\n",
        "test = tf.data.Dataset.from_tensor_slices({\"context_article_id\":test_article.values,\n",
        "                                            \"label_article_id\":test_target.values})"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "cMsHmoGgUqTO",
        "outputId": "c93b2caa-67ba-42cd-a57b-91014f26acac"
      },
      "outputs": [],
      "source": [
        "for x in train.take(1).as_numpy_iterator():\n",
        "  pprint.pprint(x)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "c7A2ROB6UvNO"
      },
      "source": [
        "#### Implementing a sequential model"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "XFNJHp-HUvNP"
      },
      "outputs": [],
      "source": [
        "#model\n",
        "embedding_dimension = 128"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "pAnEBrjUWheY"
      },
      "outputs": [],
      "source": [
        "query_model = tf.keras.Sequential([\n",
        "    tf.keras.layers.StringLookup(\n",
        "      vocabulary=unique_articles_ids, mask_token=None),\n",
        "    tf.keras.layers.Embedding(len(unique_articles_ids) + 1, embedding_dimension), \n",
        "    tf.keras.layers.GRU(embedding_dimension),\n",
        "])"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "qQpy7R1aUvNQ"
      },
      "outputs": [],
      "source": [
        "candidate_model = tf.keras.Sequential([\n",
        "  tf.keras.layers.StringLookup(\n",
        "      vocabulary=unique_articles_ids, mask_token=None),\n",
        "  tf.keras.layers.Embedding(len(unique_articles_ids) + 1, embedding_dimension)\n",
        "])"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "5YWGws_WUvNQ"
      },
      "outputs": [],
      "source": [
        "articles = tf.data.Dataset.from_tensor_slices(unique_articles_ids)\n",
        "\n",
        "metrics = tfrs.metrics.FactorizedTopK(\n",
        "    candidates=articles.batch(128).map(candidate_model)\n",
        ")\n",
        "\n",
        "task = tfrs.tasks.Retrieval(\n",
        "  metrics=metrics\n",
        ")\n",
        "\n",
        "class Model(tfrs.models.Model):\n",
        "\n",
        "    def __init__(self, query_model, candidate_model):\n",
        "      super().__init__()\n",
        "      self._query_model = query_model\n",
        "      self._candidate_model = candidate_model\n",
        "\n",
        "      self._task = task\n",
        "\n",
        "    def compute_loss(self, features, training=False):\n",
        "        watch_history = features[\"context_article_id\"]\n",
        "        watch_next_label = features[\"label_article_id\"]\n",
        "\n",
        "        query_embedding = self._query_model(watch_history)       \n",
        "        candidate_embedding = self._candidate_model(watch_next_label)\n",
        "\n",
        "        return self._task(query_embedding, candidate_embedding, compute_metrics=not training)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "xZRLy9jZUvNQ"
      },
      "outputs": [],
      "source": [
        "#model fitting\n",
        "model2 = Model(query_model, candidate_model)\n",
        "model2.compile(optimizer=tf.keras.optimizers.Adagrad(learning_rate=0.01))"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "KLoKSucCUvNR"
      },
      "outputs": [],
      "source": [
        "cached_train = train.shuffle(10_000).batch(12800).cache()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "_qO5NgbLUvNR"
      },
      "outputs": [],
      "source": [
        "cached_test = test.shuffle(10_000).batch(2560).cache()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "Sj6Eo2raUvNR",
        "outputId": "5d1339db-727d-4f8d-8833-f8357b125bf3"
      },
      "outputs": [],
      "source": [
        "model2.fit(cached_train, epochs=10)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "Kjwo2OLRUvNR",
        "outputId": "20026a03-417a-45c5-ea93-2a5bea33ac0f"
      },
      "outputs": [],
      "source": [
        "model2.evaluate(cached_test, return_dict=True)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "By2D4IDnnJGT"
      },
      "outputs": [],
      "source": []
    }
  ],
  "metadata": {
    "accelerator": "GPU",
    "colab": {
      "collapsed_sections": [
        "zJ0fsXQ8b-Vo",
        "jQVV1c7ZcPhs"
      ],
      "machine_shape": "hm",
      "provenance": []
    },
    "kernelspec": {
      "display_name": "Python 3",
      "language": "python",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.7.3"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}
